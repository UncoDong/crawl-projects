{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 引入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "# -*-  coding: utf-8 -*-\n",
    "# Author: cw\n",
    "# Datetime : 2020\n",
    "# software: PyCharm\n",
    "# 收获：\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import FirefoxProfile\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import math\n",
    "import time\n",
    "import logging\n",
    "#from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 很多小工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载文书\n",
    "def download(index='0'):\n",
    "    try:\n",
    "        quanxuan = browser.find_element_by_xpath('/html/body/div/div[4]/div[2]//div[2]/div[4]/a[1]')\n",
    "        # browser.execute_script(\"arguments[0].style.visibility='hidden'\", quanxuan)\n",
    "        element = browser.find_element_by_xpath(\"//div[@class='List_label clearfix']\")\n",
    "        browser.execute_script(\"arguments[0].style.visibility='hidden'\", element)\n",
    "        element = browser.find_element_by_xpath(\"//div[@class='LM_list']\")\n",
    "        browser.execute_script(\"arguments[0].style.visibility='hidden'\", element)\n",
    "\n",
    "        quanxuan.click()\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "        download = browser.find_element_by_xpath('/html/body/div/div[4]/div[2]//div[2]/div[4]/a[3]')\n",
    "        download.click()\n",
    "    except:\n",
    "        print('无法下载',get_rules(),index)\n",
    "      \n",
    "    \n",
    "# 循环删除某个条件\n",
    "def delete_rule_each(rule_text):\n",
    "    search_rule = browser.find_element_by_xpath(\"/html/body/div/div[4]/div[2]//div/div/div[2]/div[2]\")\n",
    "    #for rule in search_rule.find_elements_by_tag_name('p'):\n",
    "    rules = search_rule.find_elements_by_tag_name('p')\n",
    "    for del_rule in rules:\n",
    "        if rule_text in del_rule.text:\n",
    "            print('删除',del_rule.text)\n",
    "            del_rule.find_element_by_tag_name('i').click()\n",
    "            time.sleep(5)\n",
    "            return\n",
    "        \n",
    "    print('没有找到那一条',rule_text,[rule.text for rule in rules])\n",
    "\n",
    "# 删除最后一个条件\n",
    "def delete_rule(rule_text):\n",
    "    search_rule = browser.find_element_by_xpath(\"/html/body/div/div[4]/div[2]//div/div/div[2]/div[2]\")\n",
    "    #for rule in search_rule.find_elements_by_tag_name('p'):\n",
    "    rules = search_rule.find_elements_by_tag_name('p')\n",
    "    del_rule = rules[-1]\n",
    "    if rule_text in del_rule.text:\n",
    "        print('删除',del_rule.text)\n",
    "        del_rule.find_element_by_tag_name('i').click()\n",
    "        time.sleep(5)\n",
    "    else:\n",
    "        print('出现未知错误，不能删掉这一条',rule_text,del_rule.text)\n",
    "        \n",
    "\n",
    "def get_rules():\n",
    "    search_rule = browser.find_element_by_xpath(\"/html/body/div/div[4]/div[2]//div/div/div[2]/div[2]\")\n",
    "    rules = search_rule.find_elements_by_tag_name('p')\n",
    "    text_list = [rule.text.split('：')[1] for rule in rules]\n",
    "    return text_list\n",
    "\n",
    "\n",
    "# 获得左边目录树\n",
    "def get_left_tree():\n",
    "    # 0: 关键字 1: 案由 2: 法院层级 3:地域及法院 4: 裁判年份 5: 审判程序 6:文书类型 7:案例等级\n",
    "    left_tree = browser.find_elements_by_xpath('/html/body/div/div[4]/div[1]//div/div[2]/ul') \n",
    "    return left_tree\n",
    "\n",
    "# 获取当前文书的数量\n",
    "def check_results_len():\n",
    "    result = browser.find_element_by_xpath(\"/html/body/div/div[4]/div[2]//div[1]/div[2]/span\")\n",
    "    return result.text\n",
    "\n",
    "xpath = '/html/body/div/div[4]/div[1]//div/div[2]/ul'\n",
    "\n",
    "# 只获取文本的第一段\n",
    "def flit_text(text):\n",
    "    return text.split('\\n')[0]\n",
    "\n",
    "# 点开新的链接后，得到当前的树\n",
    "def each_time_find_tree(deep_list,tree,xpath):\n",
    "#     print(deep_list,flit_text(tree.text))\n",
    "    if deep_list == []:\n",
    "        return tree,xpath\n",
    "    else:\n",
    "        xpath+=f'/ul/li[{deep_list[0]+1}]'\n",
    "#         print(deep_list,xpath)\n",
    "        tree = get_anyou_from_lefttree(xpath)\n",
    "        return each_time_find_tree(deep_list[1:],tree,xpath)\n",
    "    \n",
    "# 得到案由\n",
    "def get_anyou_from_lefttree(xpath):\n",
    "    anyou = browser.find_elements_by_xpath('/html/body/div/div[4]/div[1]//div/div[2]/ul')[1]\n",
    "    return anyou.find_element_by_xpath(xpath)\n",
    "\n",
    "def show_15():\n",
    "    wait = WebDriverWait(browser,10)\n",
    "    time.sleep(1)\n",
    "    from selenium.webdriver.support.select import Select\n",
    "    selector =Select(browser.find_element_by_xpath(\"/html/body/div/div[4]/div[2]//div[8]/div/select\"))\n",
    "    selector.select_by_index(2)\n",
    "    # 直到第15个元素出现\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div/div[4]/div[2]//div[17]')))\n",
    "    # wait.until(len(browser.find_elements_by_xpath(\"/html/body/div/div[4]/div[2]//div[@class='LM_list']\")) == 15)\n",
    "\n",
    "# 点击的path的操作\n",
    "def click_xpath(xpath):\n",
    "    button = browser.find_element_by_xpath(xpath)\n",
    "    button.click() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 递归相关全部代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照年份搜索 指定年份\n",
    "def search_by_year_special(year_name):\n",
    "    left_tree = get_left_tree()\n",
    "    years = get_left_tree()[4].find_elements_by_tag_name('li')\n",
    "    print([each.text for each in years])\n",
    "    for year in years:\n",
    "        if year_name == year.text.split('(')[0]:\n",
    "            if year.find_elements_by_tag_name('a') and year.find_element_by_tag_name('a').is_displayed():\n",
    "                year.find_element_by_tag_name('a').click()\n",
    "                time.sleep(10)\n",
    "                print('成功选择条件',year_name)\n",
    "                search_by_type()\n",
    "            else:\n",
    "                print(year_name,'爬不了')\n",
    "            return\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# 按照年份搜索（第一层）\n",
    "def search_by_year():\n",
    "    left_tree = get_left_tree()\n",
    "    for i in range(len(left_tree[4].find_elements_by_tag_name('li'))):\n",
    "        years = get_left_tree()[4].find_elements_by_tag_name('li')\n",
    "        print('当前的年份',[year.text for year in years])\n",
    "        if i < len(years) and years[i].find_elements_by_tag_name('a') and years[i].find_element_by_tag_name('a').is_displayed():\n",
    "            years[i].find_element_by_tag_name('a').click()\n",
    "            time.sleep(5)\n",
    "            # \n",
    "            if int(check_results_len()) <= 615:\n",
    "                print(get_rules(),'当前条件小于600条，开始爬取',int(check_results_len()))\n",
    "                crwal()\n",
    "                time.sleep(5)\n",
    "            # 第二层 按照案件类型搜索\n",
    "            else:\n",
    "                print(get_rules(),'当前条件大于600条，调用文书类型递归',int(check_results_len()))\n",
    "                search_by_type()\n",
    "                time.sleep(5)\n",
    "            delete_rule('裁判年份')\n",
    "        \n",
    "# 根据文书类型选择（第二层）\n",
    "def search_by_type():\n",
    "    left_tree = get_left_tree()\n",
    "    for i in range(len(left_tree[6].find_elements_by_tag_name('li'))):\n",
    "        text_type = get_left_tree()[6].find_elements_by_tag_name('li')\n",
    "        print('当前的type',[year.text for year in text_type])\n",
    "        if i < len(text_type) and text_type[i].find_elements_by_tag_name('a') and text_type[i].find_element_by_tag_name('a').is_displayed():\n",
    "            text_type[i].find_element_by_tag_name('a').click()\n",
    "            time.sleep(5)\n",
    "            if int(check_results_len()) <= 615:\n",
    "                print(get_rules(),'当前条件小于600条，开始爬取',int(check_results_len()))\n",
    "                crwal()\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(get_rules(),'当前条件大于600条，调用案由递归',int(check_results_len()))\n",
    "                search_by_case_tree()\n",
    "                time.sleep(5)\n",
    "            delete_rule('文书类型')\n",
    "        \n",
    "# 使用深度遍历的方法得到树\n",
    "def dfs_get_tree(deep_list,tree,deep,xpath):\n",
    "    if deep == len(deep_list):\n",
    "        return tree\n",
    "    else:\n",
    "        #print('当前的tree节点',flit_text(tree.text))\n",
    "#         tree = get_anyou_from_lefttree(xpath)\n",
    "        #print([each.text for each in  tree])\n",
    "        #tree = tree[deep_list[deep]]\n",
    "        print(deep,deep_list[deep],flit_text(tree.text))\n",
    "        # 如果已经点开了\n",
    "        if tree.find_elements_by_xpath('./ul'):\n",
    "            print('已经点开了',flit_text(tree.text))\n",
    "            # 进入到案由模块\n",
    "            left_tree = get_left_tree()[1]\n",
    "            # 得到现在的树节点\n",
    "            tree,_ = each_time_find_tree(deep_list[:deep+1],left_tree,xpath)\n",
    "#             print('now in ',flit_text(tree.text))\n",
    "            return dfs_get_tree(deep_list,tree,deep+1,xpath)\n",
    "        else:\n",
    "            print('还没点开',flit_text(tree.text))\n",
    "            if tree.find_elements_by_tag_name('i') and tree.find_elements_by_tag_name('i')[0].is_displayed():\n",
    "                # 点开加号并且重新获取tree\n",
    "                tree.find_elements_by_tag_name('i')[0].click()\n",
    "                time.sleep(5)\n",
    "                # 进入到案由模块\n",
    "                left_tree = get_left_tree()[1]\n",
    "                # 得到现在的树节点\n",
    "                # 因为传进来的deep_list少了一位，所以判断的deep要加一位\n",
    "                tree,_ = each_time_find_tree(deep_list[:deep+1],left_tree,xpath)\n",
    "    #             print('now in ',flit_text(tree.text))\n",
    "                return dfs_get_tree(deep_list,tree,deep+1,xpath)\n",
    "            else:\n",
    "                print('点不开',tree.text.split())\n",
    "                return tree\n",
    "\n",
    "\n",
    "def get_now_tree(deep_list):\n",
    "    # 进入到案由模块\n",
    "    left_tree = get_left_tree()[1]\n",
    "    # 如果是空的，那就直接返回案由模块\n",
    "    if deep_list == []:\n",
    "        return left_tree\n",
    "    else:\n",
    "        # 第一层直接获得对应的值\n",
    "        left_tree = left_tree.find_elements_by_tag_name('li')\n",
    "        #print(left_tree[0].text)\n",
    "                 #/html/body/div/div[4]/div[1]/d/div/div[2] \n",
    "            \n",
    "        xpath = f'./li[{deep_list[0]+1}]'\n",
    "        # xpath会匹配很多，只有第二个才是\n",
    "        tree = get_anyou_from_lefttree(xpath)\n",
    "        if 'jstree-closed' in tree.get_attribute('class'):\n",
    "            if tree.find_elements_by_tag_name('i') and tree.find_elements_by_tag_name('i')[0].is_displayed():\n",
    "                # 点开加号并且重新获取tree\n",
    "                tree.find_elements_by_tag_name('i')[0].click()\n",
    "                time.sleep(10)\n",
    "                tree = get_now_tree(deep_list)\n",
    "                print('有加号点一下',flit_text(tree.text))\n",
    "                \n",
    "                \n",
    "        return dfs_get_tree(deep_list[1:], tree,0,xpath)\n",
    "    \n",
    "import re\n",
    "def search_by_list(deep_list):\n",
    "    \n",
    "    tree = get_now_tree(deep_list)\n",
    "    print('1 get_now_tree的位置',deep_list,tree.text.split('\\n'),tree.get_attribute('class'),'有无列表：',len(tree.find_elements_by_tag_name('ul')))\n",
    "\n",
    "    # 如果当前有加号\n",
    "    if 'jstree-closed' in tree.get_attribute('class'):\n",
    "        if tree.find_elements_by_tag_name('i') and tree.find_elements_by_tag_name('i')[0].is_displayed():\n",
    "            # 点开加号并且重新获取tree\n",
    "            print('有加号点一下',flit_text(tree.text))\n",
    "            tree.find_elements_by_tag_name('i')[0].click()\n",
    "            time.sleep(10)\n",
    "            tree = get_now_tree(deep_list)\n",
    "            #print('2 当前树的位置',deep_list,flit_text(tree.text),tree.get_attribute('class'),tree.find_elements_by_tag_name('ul'))\n",
    "            print('2 get_now_tree的位置',deep_list,flit_text(tree.text),tree.get_attribute('class'),'有无列表：',len(tree.find_elements_by_tag_name('ul')))\n",
    "            \n",
    "        \n",
    "        \n",
    "    number = re.findall(\"\\((\\d+)\\)\",tree.text)[0]\n",
    "    # 如能够找到子树 且数量大于600\n",
    "    if len(tree.find_elements_by_tag_name('ul')) and int(number) > 600:\n",
    "        #print('could find son',deep_list,flit_text(tree.text))\n",
    "        \n",
    "        case_list = tree.find_element_by_tag_name('ul').find_elements_by_tag_name('li')\n",
    "        case_list_len = len(case_list)\n",
    "        #print('长度为',case_list_len)\n",
    "        for i in range(case_list_len):\n",
    "            # 刷新页面后要重新获取一次\n",
    "            root_tree = get_now_tree(deep_list)\n",
    "            #print('3 当前树的位置',deep_list,flit_text(root_tree.text),root_tree.get_attribute('class'),root_tree.find_elements_by_tag_name('ul'))\n",
    "            case_list = root_tree.find_element_by_tag_name('ul').find_elements_by_tag_name('li')\n",
    "            # 获取当前的案件名称\n",
    "            case = case_list[i]\n",
    "\n",
    "            print([each.text for each in  case_list],case.text)\n",
    "            \n",
    "            number = re.findall(\"\\((\\d+)\\)\",case.text)[0]\n",
    "            if int(number) <= 615:\n",
    "                print('1 当前选择的文书类型为',flit_text(case.text))\n",
    "                if case.find_elements_by_tag_name('a') and case.find_elements_by_tag_name('a')[0].is_displayed():\n",
    "                        case.find_elements_by_tag_name('a')[0].click()\n",
    "                        print('开始爬取')\n",
    "                        crwal()\n",
    "                        time.sleep(5)\n",
    "                        delete_rule('案由')\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # 有一种情况是，点开加号后，里面没东西\n",
    "                if 'jstree-closed' in case.get_attribute('class'):\n",
    "                    #print('有加号点一下',flit_text(case.text))\n",
    "                    if case.find_elements_by_tag_name('i') and case.find_elements_by_tag_name('i')[0].is_displayed():\n",
    "                        case.find_elements_by_tag_name('i')[0].click()\n",
    "                        time.sleep(10)\n",
    "                        # 点开加号并且重新获取tree\n",
    "                        root_tree = get_now_tree(deep_list)\n",
    "                        #print('3 当前树的位置',deep_list,flit_text(root_tree.text),root_tree.get_attribute('class'),root_tree.find_elements_by_tag_name('ul'))\n",
    "                        case_list = root_tree.find_element_by_tag_name('ul').find_elements_by_tag_name('li')\n",
    "                        # 获取当前的案件名称\n",
    "                        case = case_list[i]\n",
    "                    \n",
    "                # 检查子树\n",
    "                plus = 'jstree-open' in case.get_attribute('class')\n",
    "                    \n",
    "                # 如果有子树\n",
    "                if plus:\n",
    "                    print('有子树',i,flit_text(case.text))\n",
    "                    print('2 当前选择的文书类型为',flit_text(case.text), '需要增加深度')\n",
    "                    # 添加一次深度\n",
    "                    deep_list_add = deep_list.copy()\n",
    "                    deep_list_add.append(i)\n",
    "                    search_by_list(deep_list_add)\n",
    "                else:\n",
    "                    print('无子树',i,flit_text(case.text))\n",
    "                    print('3 当前选择的文书类型为',flit_text(case.text))\n",
    "                    # 直接选中当前标签的话需要用这个\n",
    "                    if case.find_elements_by_tag_name('a') and case.find_element_by_tag_name('a').is_displayed():\n",
    "                        case.find_element_by_tag_name('a').click()\n",
    "                        print('开始爬取')\n",
    "                        crwal()\n",
    "                        time.sleep(5)\n",
    "                        delete_rule('案由')\n",
    "    else:\n",
    "        print('没有子节点或者当前数字小于600',tree.text.split('\\n'),number)\n",
    "        print('4 当前选择的文书类型为',flit_text(tree.text))\n",
    "        # 直接选中当前标签的话需要用这个\n",
    "        if tree.find_elements_by_tag_name('a'):\n",
    "            if tree.find_elements_by_tag_name('a') and tree.find_element_by_tag_name('a').is_displayed():\n",
    "                tree.find_element_by_tag_name('a').click()\n",
    "                print('开始爬取')\n",
    "                crwal()\n",
    "                time.sleep(5)\n",
    "                delete_rule('案由')\n",
    "    \n",
    "\n",
    "# 深度和要访问的下标\n",
    "def search_by_case_tree(deep_list = []):\n",
    "    print('当前要爬取的',get_rules(),deep_list)\n",
    "    try: \n",
    "        if deep_list == []:\n",
    "            root_tree = get_now_tree(deep_list)\n",
    "            root_len = len(root_tree.find_elements_by_tag_name('li'))\n",
    "            for i in range(root_len):\n",
    "    #             root_tree = get_now_tree(deep_list)\n",
    "    #             tree = root_tree.find_elements_by_tag_name('li')[i]\n",
    "                root_tree = get_now_tree(deep_list)\n",
    "                print('第一个节点',flit_text(root_tree.find_elements_by_tag_name('li')[i].text),i)\n",
    "                return_tree = search_by_list([i])\n",
    "        else:\n",
    "            search_by_list(deep_list)\n",
    "    except:\n",
    "        import traceback\n",
    "\n",
    "        print('error 出错了',get_rules(),deep_list,traceback.format_exc())\n",
    "        \n",
    "        \n",
    "# 爬取每一页的内容\n",
    "def crwal():\n",
    "    try:\n",
    "        show_15()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    for i in range(int(600/15)):\n",
    "        page_div = browser.find_elements_by_xpath('//*[@id=\"_view_1545184311000\"]/div')\n",
    "        \n",
    "        rules = get_rules()\n",
    "        rules.append(str(i))\n",
    "        print(rules)\n",
    "        save_name = '_'.join(rules)\n",
    "        \n",
    "        \n",
    "        download(str(i))\n",
    "        if len(page_div)!=18:\n",
    "            print('已经到达末尾页')\n",
    "            return\n",
    "        page_div = browser.find_elements_by_xpath('//*[@id=\"_view_1545184311000\"]/div')\n",
    "        pages = page_div[-1].find_elements_by_tag_name('a')\n",
    "        \n",
    "        # 点击下一页\n",
    "        next_page = pages[-2].text\n",
    "        #print('下一页的元素',next_page)\n",
    "        try:\n",
    "            pages[-1].click()\n",
    "        except:\n",
    "            print('已经到达末尾页')\n",
    "            return\n",
    "        \n",
    "\n",
    "        # 直到下一页出现\n",
    "    #     wait.until(EC.presence_of_element_located((By.XPATH, f'/html/body/div/div[4]/div[2]//div[18]/a[{next_page}]')))\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化+登录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 无图\n",
    "profile = FirefoxProfile()\n",
    "profile.set_preference('browser.migration.version', 9001)\n",
    "profile.set_preference('permissions.default.image', 2)\n",
    "\n",
    "\n",
    "profile.set_preference('browser.helperApps.neverAsk.saveToDisk','application/octet-stream')\n",
    "profile.set_preference('browser.download.dir', 'E:\\判决文书\\judment_learning\\中国裁判文书网\\save')\n",
    "\n",
    "\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    " \n",
    " \n",
    "\n",
    "browser = webdriver.Firefox(firefox_profile=profile)\n",
    "\n",
    "\n",
    "\"\"\"网页获取\"\"\"\n",
    "browser.get('http://wenshu.court.gov.cn')\n",
    "time.sleep(5)\n",
    "login = browser.find_element_by_xpath('/html/body/div[1]/div[2]/ul/li[1]/a')\n",
    "login.click()\n",
    "wait = WebDriverWait(browser,10)\n",
    "time.sleep(5)\n",
    "browser.switch_to.frame('contentIframe')\n",
    "\n",
    "phone = browser.find_element_by_xpath('/html/body/div/div/form/div[1]/div[1]/div/div/div/input') \n",
    "phone.clear()\n",
    "phone.send_keys('用户名')\n",
    "time.sleep(1)\n",
    "\n",
    "pwd = browser.find_element_by_xpath('/html/body/div/div/form/div[1]/div[2]/div/div/div/input') \n",
    "pwd.clear()\n",
    "pwd.send_keys('密码')\n",
    "time.sleep(1)\n",
    "\n",
    "login = browser.find_element_by_xpath('/html/body/div/div/form/div[3]/span')\n",
    "login.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 法院名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list = ['武汉市新洲区人民法院', '武汉市洪山区人民法院', \n",
    "             '武汉市江夏区人民法院', '武汉市青山区人民法院 ',\n",
    "            '武汉市硚口区人民法院','武汉市江汉区人民法院','武汉市武昌区人民法院',\n",
    "            '武汉市东西湖区人民法院','武汉市江岸区人民法院','武汉市汉阳区人民法院',\n",
    "             '武汉市汉南区人民法院','武汉经济技术开发区人民法院','武汉市黄陂区人民法院','武汉市蔡甸区人民法院']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照年份爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前爬取 武汉市新洲区人民法院\n",
      "['15']\n",
      "没有找到那一条 裁判年份 ['法院名称：武汉市新洲区人民法院', '公开类型：文书公开']\n",
      "没有找到那一条 文书类型 ['法院名称：武汉市新洲区人民法院', '公开类型：文书公开']\n",
      "没有找到那一条 案由 ['法院名称：武汉市新洲区人民法院', '公开类型：文书公开']\n",
      "['2021(119)', '2020(5741)', '2019(5310)', '2018(4422)', '2017(4122)', '2016(3343)', '2015(2593)', '2014(2927)', '2013(37)', '2012(2)', '2010(1)', '2009(1)']\n",
      "成功选择条件 2020\n",
      "当前的type ['判决书(2488)', '裁定书(3246)', '调解书(2)', '决定书(5)']\n",
      "['武汉市新洲区人民法院', '文书公开', '2020', '判决书'] 当前条件大于600条，调用案由递归 2488\n",
      "当前要爬取的 ['武汉市新洲区人民法院', '文书公开', '2020', '判决书'] []\n",
      "第一个节点 刑事案由(586) 0\n",
      "有加号点一下 刑事案由(586)\n",
      "1 get_now_tree的位置 [0] ['刑事案由(586)', '危害公共安全罪(322)', '破坏社会主义市场经济秩序罪(1)', '侵犯公民人身权利、民主权利罪(58)', '侵犯财产罪(105)', '妨害社会管理秩序罪(98)', '贪污贿赂罪(9)'] jstree-node jstree-open 有无列表： 1\n",
      "没有子节点或者当前数字小于600 ['刑事案由(586)', '危害公共安全罪(322)', '破坏社会主义市场经济秩序罪(1)', '侵犯公民人身权利、民主权利罪(58)', '侵犯财产罪(105)', '妨害社会管理秩序罪(98)', '贪污贿赂罪(9)'] 586\n",
      "4 当前选择的文书类型为 刑事案由(586)\n",
      "开始爬取\n",
      "['武汉市新洲区人民法院', '文书公开', '2020', '判决书', '刑事案由', '0']\n",
      "['武汉市新洲区人民法院', '文书公开', '2020', '判决书', '刑事案由', '1']\n",
      "['武汉市新洲区人民法院', '文书公开', '2020', '判决书', '刑事案由', '2']\n"
     ]
    }
   ],
   "source": [
    "for city in city_list:\n",
    "    print('当前爬取',city)\n",
    "    num=browser.window_handles\n",
    "    print(num)\n",
    "    browser.switch_to.window(num[0])\n",
    "    \n",
    "    try:\n",
    "        delete_rule_each('裁判年份')\n",
    "        time.sleep(3)\n",
    "        delete_rule_each('文书类型')\n",
    "        time.sleep(3)\n",
    "        delete_rule_each('案由')\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    # 点击高级搜索\n",
    "    adv_search = browser.find_element_by_xpath(\"/html/body/div/div[3]//div/div[1]/div[1]\")\n",
    "    adv_search.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    name = city\n",
    "    name_input = browser.find_element_by_xpath('//*[@id=\"s2\"]')\n",
    "    name_input.clear()\n",
    "    for each in name:\n",
    "        name_input.send_keys(each)\n",
    "        time.sleep(0.25)\n",
    "\n",
    "\n",
    "    # 选择文书公开\n",
    "    # 点击公开类型\n",
    "    browser.find_element_by_xpath(\"/html/body/div/div[3]//div/div[3]/div[1]/div[12]/div/div/div\").click()\n",
    "    time.sleep(2)\n",
    "    # 选择文书公开\n",
    "    browser.find_element_by_xpath(\"/html/body/div/div[3]//div/div[3]/div[1]/div[12]/div/div/ul/li[2]\").click()\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "    search = browser.find_element_by_xpath('//*[@id=\"searchBtn\"]')\n",
    "    search.click() \n",
    "    time.sleep(5)\n",
    "\n",
    "    search_by_year_special('2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全量爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in city_list:\n",
    "    num=browser.window_handles\n",
    "    print(num)\n",
    "    browser.switch_to.window(num[0])\n",
    "    \n",
    "    try:\n",
    "        delete_rule_each('裁判年份')\n",
    "        time.sleep(3)\n",
    "        delete_rule_each('文书类型')\n",
    "        time.sleep(3)\n",
    "        delete_rule_each('案由')\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    # 点击高级搜索\n",
    "    adv_search = browser.find_element_by_xpath(\"/html/body/div/div[3]//div/div[1]/div[1]\")\n",
    "    adv_search.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    name = city\n",
    "    name_input = browser.find_element_by_xpath('//*[@id=\"s2\"]')\n",
    "    name_input.clear()\n",
    "    for each in name:\n",
    "        name_input.send_keys(each)\n",
    "        time.sleep(0.25)\n",
    "\n",
    "\n",
    "    # 选择文书公开\n",
    "    # 点击公开类型\n",
    "    browser.find_element_by_xpath(\"/html/body/div/div[3]//div/div[3]/div[1]/div[12]/div/div/div\").click()\n",
    "    time.sleep(2)\n",
    "    # 选择文书公开\n",
    "    browser.find_element_by_xpath(\"/html/body/div/div[3]//div/div[3]/div[1]/div[12]/div/div/ul/li[2]\").click()\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "    search = browser.find_element_by_xpath('//*[@id=\"searchBtn\"]')\n",
    "    search.click() \n",
    "    time.sleep(5)\n",
    "\n",
    "    search_by_year()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
